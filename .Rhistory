# the distribution of word
tabn<-table(str_length(words_html))/length(words_html)
barplot(tabn,main="word length Distribution")
sort(table(words_html), decreasing = TRUE)[1:10]
str_extract_all(words_html,str_length=5)
five_words <- sample(words_html,5)
five_words <- sample(words_html,5)
five_words
tab_n<-table(str_length(words_html))/length(words_html)
barplot(tab_n,main="word length Distribution")
table
tab_n
five_words <- list()
five_words <- list()
for (i in words_html){
if (str_length(i) == "5"){
append(five_words,i)
}
}
five_words
five_words <- list()
for (i in words_html){
if (str_length(i) == "5"){
append(i,five_words)
}
}
five_words
five_words <- list()
for (i in words_html){
if (str_length(i) == "5"){
print i
five_words <- list()
for (i in words_html){
if (str_length(i)= "5"){
five_words <- list()
for (i in words_html){
if (str_length(i)= "5"){
five_words <- list()
for (i in words_html){
if (str_length(i)= 5){
five_words <- list()
for (i in words_html){
if str_length(i)= 5{
five_words <- list()
for (i in words_html){
if (str_length(i)== 5){
print (i)
}
}
five_words <- list()
for (i in words_html){
if (str_length(i)== 5){
five_words.append(i)
}
}
five_words <- list()
for (i in words_html){
if (str_length(i)== 5){
five_words <-append(five_words,i)
}
}
five_words
five_words <- list()
for (i in words_html){
if (str_length(i)== 5){
five_words <-insert(five_words,i)
}
}
five_words <- list()
for (i in length(words_html)){
if (str_length(words_html[i])== 5){
list.insert(five_words[i],i)
}
}
five_words
for (i in length(words_html)){
if (str_length(words_html[i])== 5){
list.insert(five_words[i],i)
}
}
five_words
y <- gsub("\\b[a-zA-Z0-9]{1,4}\\b", "", words_html) # replace words shorter than 4
y_2 <- gsub("\\b[a-zA-Z0-9]{5,}\\b", "", y) # replace words longer than 10
y_2
y <- gsub("\\b[a-zA-Z0-9]{1,4}\\b",0, words_html) # replace words shorter than 4
y_2 <- gsub("\\b[a-zA-Z0-9]{5,}\\b",0, y) # replace words longer than 10
y_2
five_words <- list()
for (i in words_html){
if (str_length(i) == "5") and {
y <- gsub("\\b[a-zA-Z0-9]{1,6}\\b", "", words_html) # replace words shorter than 4
y <- gsub("\\b[a-zA-Z0-9]{5,}\\b", "", y) # replace words longer than 10
five_words <- list()
for (i in words_html){
if (str_length(i) == "5") and {
y <- gsub("\\b[a-zA-Z0-9]{1,6}\\b", "", words_html) # replace words shorter than 4
y_2 <- gsub("\\b[a-zA-Z0-9]{5,}\\b", "", y) # replace words longer than 10
y_2
five_words <- list()
for (i in words_html){
if (str_length(i) == "5") and {
y <- gsub("\\b[a-zA-Z0-9]{1,4}\\b", "", words_html) # replace words shorter than 4
y_2 <- gsub("\\b[a-zA-Z0-9]{5,}\\b", "", y) # replace words longer than 10
y_2
five_words <- list()
for (i in words_html){
if (str_length(i) == "5") and {
y <- gsub("\\b[a-zA-Z0-9]{1,4}\\b", "", words_html) # replace words shorter than 4
y_2 <- gsub("\\b[a-zA-Z0-9]{6,}\\b", "", y) # replace words longer than 10
y_2
five_words <- list()
for (i in words_html){
if (str_length(i) == "5") and {
y <- gsub("\\b[a-zA-Z0-9]{1,4}\\b", 0, words_html) # replace words shorter than 4
y_2 <- gsub("\\b[a-zA-Z0-9]{6,}\\b", 0, y) # replace words longer than 10
y_2
five_words <- list()
for (i in words_html){
if (str_length(i) == "5") and {
y <- gsub("\\b[a-zA-Z0-9]{1,4}\\b", 0, words_html) # replace words shorter than 4
y_2 <- gsub("\\b[a-zA-Z0-9]{6,}\\b", 0, y) # replace words longer than 10
y_2
five_words <- list()
for (i in words_html){
if (str_length(i) == "5") and {
five_words <- list()
for (i in words_html){
if (str_length(i) == 5) {
print(i)
}
}
y <- gsub("!?#\\b+", "", words_html) # remove leftover hash characters from hashtags
y_2 <- gsub("^\\s+|\\s+$", "", y) # remove leading and trailing whitespaces
y_2
y <- gsub("{}%-!?#\\b+", "", words_html) # remove leftover hash characters from hashtags
y <- gsub("\?\/\!#\\b+", "", words_html) # remove leftover hash characters from hashtags
y <- gsub("#\\b+", "", words_html) # remove leftover hash characters from hashtags
y_2 <- gsub("^\\s+|\\s+$", "", y) # remove leading and trailing whitespaces
y_2
five_words <- list()
for (i in words_html){
if (str_length(i) == 5) {
print(i)
}
}
five_words
y <- gsub("#\\b+", "", words_html) # remove leftover hash characters from hashtags
y_2 <- gsub("^\\s+|\\s+$", "", y) # remove leading and trailing whitespaces
y_3 <-  gsub("[:punct:]", "", y_2)
y_3
y <- gsub("#\\b+", "", words_html) # remove leftover hash characters from hashtags
y_2 <- gsub("^\\s+|\\s+$", y) # remove leading and trailing whitespaces
y <- gsub("#\\b+", "", words_html) # remove leftover hash characters from hashtags
y_2 <- gsub("^\\s+|\\s+$", y) # remove leading and trailing whitespaces
five_letter <- words_Moby[-str_which(words_html,"[^a-z, ]+")]
five_letter <- words_html[-str_which(words_html,"[^a-z, ]+")]
five_letter <-str_subset(five_letter, "^.....$")
five_letter <- str_to_lower(five_letter)
words_left <- length(words_html) - (length(five_letter))
words_left
five_word_rep <- table(five_letter)
uni_words_left <- length(word_rep) - (length(five_word_rep))
five_letter <- words_html[-str_which(words_html,"[^a-z, ]+")]
five_letter <-str_subset(five_letter, "^.....$")
five_letter <- str_to_lower(five_letter)
five_letter
five_word_rep
sort(five_word_rep, decreasing = TRUE)[1:10]
clean_words <- words_html[-str_which(words_html,"[^a-z, ]+")]
clean_five_letter <-str_subset(clean_words, "^.....$")
five_letter_little<- str_to_lower(clean_five_letter)
five_word_rep <- table(five_letter_little)
sort(five_word_rep, decreasing = TRUE)[1:10]
#clean data
clean_words <- words_html[-str_which(words_html,"[^a-z, ]+")]
clean_five_letter <-str_subset(clean_words, "^.....$")
five_letter_little<- str_to_lower(clean_five_letter)
five_letter_tab <- table(five_letter_little)
#most frequent five-letter words with their frequencies
sort(five_word_rep, decreasing = TRUE)[1:10]
#
dis <- length(five_letter_tab)-length(five_letter_little)
dis
#clean data
clean_words <- words_html[-str_which(words_html,"[^a-z, ]+")]
clean_five_letter <-str_subset(clean_words, "^.....$")
five_letter_little<- str_to_lower(clean_five_letter)
five_letter_tab <- table(five_letter_little)
#most frequent five-letter words with their frequencies
sort(five_word_rep, decreasing = TRUE)[1:10]
#
dis <- length(words_html)-length(five_letter_little)
dis
dis
unique(five_letter_little)
unique_all_word <-unique(clean_words)
unique_five_words <-unique(five_letter_little)
Number_dif <- length(unique_all_word)-length(unique_five_words)
Number_dif
five_letter_little_2 <- five_letter_little
etter_freq_pos <-
tibble(word = five_letter_little_2) %>%
select(word) %>%
mutate(letter = word) %>%
tidyr::separate_rows(letter, sep = "") %>%
filter(letter != "") %>%
group_by(word) %>%
mutate(position = row_number()) %>%
group_by(letter, position) %>%
summarize(n = n(), .groups = "drop") %>%
mutate(
five_letter_little_2 = letter_freq[letter] * length(!!five_letter_little_2),
freq = n / five_letter_little_2
) %>%
select(-n, -five_letter_little_2) %>%
tidyr::pivot_wider(
names_from = position,
values_from = freq,
values_fill = 0,
names_prefix = "p"
)
letter_freq <-
five_letter_little_2 %>%
# Split each word into a vector of letters
str_split("") %>%
# Keep one of each letter per word
map(unique) %>%
# Unlist into a big vector of letters
unlist() %>%
# Count the letters (each appearance in a word)
table() %>%
# Most popular letters first
sort(decreasing = TRUE) %>%
# Turn into frequency table
`/`(length(five_letter_little_2)) %>%
# Remove attributes from table()
c()
etter_freq_pos <-
tibble(word = five_letter_little_2) %>%
select(word) %>%
mutate(letter = word) %>%
tidyr::separate_rows(letter, sep = "") %>%
filter(letter != "") %>%
group_by(word) %>%
mutate(position = row_number()) %>%
group_by(letter, position) %>%
summarize(n = n(), .groups = "drop") %>%
mutate(
five_letter_little_2 = letter_freq[letter] * length(!!five_letter_little_2),
freq = n / five_letter_little_2
) %>%
select(-n, -five_letter_little_2) %>%
tidyr::pivot_wider(
names_from = position,
values_from = freq,
values_fill = 0,
names_prefix = "p"
)
letter_freq_pos
letter_freq <-
five_letter_little_2 %>%
# Split each word into a vector of letters
str_split("") %>%
# Keep one of each letter per word
map(unique) %>%
# Unlist into a big vector of letters
unlist() %>%
# Count the letters (each appearance in a word)
table() %>%
# Most popular letters first
sort(decreasing = TRUE) %>%
# Turn into frequency table
`/`(length(five_letter_little_2)) %>%
# Remove attributes from table()
c()
letter_freq_pos <-
tibble(word = five_letter_little_2) %>%
select(word) %>%
mutate(letter = word) %>%
tidyr::separate_rows(letter, sep = "") %>%
filter(letter != "") %>%
group_by(word) %>%
mutate(position = row_number()) %>%
group_by(letter, position) %>%
summarize(n = n(), .groups = "drop") %>%
mutate(
five_letter_little_2 = letter_freq[letter] * length(!!five_letter_little_2),
freq = n / five_letter_little_2
) %>%
select(-n, -five_letter_little_2) %>%
tidyr::pivot_wider(
names_from = position,
values_from = freq,
values_fill = 0,
names_prefix = "p"
)
letter_freq_pos
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
# Read the html into r:
webpage <- read_html(url)
# In line 35, We are creating the first paragraph, and then extract the first line out of it. In line 36 we're returning the sentence.
first_sentence <- webpage %>% html_nodes("div") %>% html_text()
first_sentence[1]
words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
words_html <- words_html[[1]]
words_html <- words_html[words_html!=""]
#count words
print(length(words_html))
# length words
words_n <-nchar(words_html)
#longest word, mean, median
max(words_n)
mean(words_n)
median(words_n)
# Create frequency table
freq_words <- sort(table(unlist(words_html)),
decreasing = TRUE)
#most common word
mcw <-which.max(freq_words)
mcw
# the distribution of word
tab_n<-table(str_length(words_html))/length(words_html)
barplot(tab_n,main="word length Distribution")
sort(table(words_html), decreasing = TRUE)[1:10]
moby_text <- html_text2(webpage)
cut_text <- str_split(moby_text, "\rErromangoan.\t\r\n\r H2 anchor\r\n\r\n\n\n\n\n\r\n\r ")[[1]][2]
chapters <- strsplit(cut_text, "\r\n\n\r\n\n\r \r \r\n\n\r\n\r\n\n\n\n\n\r\n\r ")
chapters <- chapters[[1]]
x_chapter_num <- c()
y_words_per_chapter <- c()
for (i in 1:length(chapters)){
fixed_chapter_i <- str_replace_all(chapters[i], "\\s+", " ")
splitsplat <- str_split(fixed_chapter_i, " ")
splitsplat <- c(splitsplat)
splitsplat <- splitsplat[[1]]
x_chapter_num[i] <- i
y_words_per_chapter[i] <- length(splitsplat)
}
barplot(y_words_per_chapter, main = "Number of Words Per Chapter",
xlab = "Chapter Number", ylab = "Words Number", names.arg = x_chapter_num,
col = "darkred")
Q2a <- function(word_query, chapters_num){
relative_freq <- c()
counter <- 1
for (i in as.numeric(chapters_num)){
relative_freq[counter] <- (str_count(chapters[i], word_query)/y_words_per_chapter[i])
counter <- counter + 1
}
return(relative_freq)
}
ahab_plot <- Q2a("Ahab", c(1:137))
barplot(ahab_plot, main = "Freq VS. Chapter for Ahab",
xlab = "Chapter Number", ylab = "Word Freq", names.arg = x_chapter_num,
col = "darkblue")
moby_plot <- Q2a("Moby", c(1:137))
barplot(moby_plot, main = "Freq VS. Chapter for Moby",
xlab = "Chapter Number", ylab = "Word Freq", names.arg = x_chapter_num,
col = "darkgreen")
sea_plot <- Q2a("sea", c(1:137))
barplot(sea_plot, main = "Freq VS. Chapter for sea",
xlab = "Chapter Number", ylab = "Word Freq", names.arg = x_chapter_num,
col = "yellow")
#clean data
clean_words <- words_html[-str_which(words_html,"[^a-z, ]+")]
clean_five_letter <-str_subset(clean_words, "^.....$")
five_letter_little<- str_to_lower(clean_five_letter)
five_letter_tab <- table(five_letter_little)
#most frequent five-letter words with their frequencies
sort(five_word_rep, decreasing = TRUE)[1:10]
five_letter_little_2 <- five_letter_little
#The difference between all the words and 5-word words
unique_all_word <-unique(clean_words)
unique_five_words <-unique(five_letter_little)
Number_dif <- length(unique_all_word)-length(unique_five_words)
Number_dif
letter_freq <-
five_letter_little_2 %>%
# Split each word into a vector of letters
str_split("") %>%
# Keep one of each letter per word
map(unique) %>%
# Unlist into a big vector of letters
unlist() %>%
# Count the letters (each appearance in a word)
table() %>%
# Most popular letters first
sort(decreasing = TRUE) %>%
# Turn into frequency table
`/`(length(five_letter_little_2)) %>%
# Remove attributes from table()
c()
letter_freq_pos <-
tibble(word = five_letter_little_2) %>%
select(word) %>%
mutate(letter = word) %>%
tidyr::separate_rows(letter, sep = "") %>%
filter(letter != "") %>%
group_by(word) %>%
mutate(position = row_number()) %>%
group_by(letter, position) %>%
summarize(n = n(), .groups = "drop") %>%
mutate(
five_letter_little_2 = letter_freq[letter] * length(!!five_letter_little_2),
freq = n / five_letter_little_2
) %>%
select(-n, -five_letter_little_2) %>%
tidyr::pivot_wider(
names_from = position,
values_from = freq,
values_fill = 0,
names_prefix = "p"
)
letter_freq_pos
# Helper function:
wordle_match <- function(guess, word)  # 1: correct location, -1: wrong location, 0: missing
{
L <- nchar(guess)
match <- rep(0, L)
for(i in 1:L)
{
if(grepl(substr(guess, i, i), word, fixed=TRUE))
{match[i] = -1}
if(substr(guess, i, i) == substr(word, i, i))
{      match[i] = 1}
}
return(match)
}
letter_freq <-
five_letter_little_2 %>%
# Split each word into a vector of letters
str_split("") %>%
# Keep one of each letter per word
map(unique) %>%
# Unlist into a big vector of letters
unlist() %>%
# Count the letters (each appearance in a word)
table() %>%
# Most popular letters first
sort(decreasing = TRUE) %>%
# Turn into frequency table
`/`(length(five_letter_little_2)) %>%
# Remove attributes from table()
c()
letter_freq_pos <-
tibble(word = five_letter_little_2) %>%
select(word) %>%
mutate(letter = word) %>%
tidyr::separate_rows(letter, sep = "") %>%
filter(letter != "") %>%
group_by(word) %>%
mutate(position = row_number()) %>%
group_by(letter, position) %>%
summarize(n = n(), .groups = "drop") %>%
mutate(
five_letter_little_2 = letter_freq[letter] * length(!!five_letter_little_2),
freq = n / five_letter_little_2
) %>%
select(-n, -five_letter_little_2) %>%
tidyr::pivot_wider(
names_from = position,
values_from = freq,
values_fill = 0,
names_prefix = "p"
)
letter_freq_pos
#clean data
clean_words <- words_html[-str_which(words_html,"[^a-z, ]+")]
clean_five_letter <-str_subset(clean_words, "^.....$")
five_letter_little<- str_to_lower(clean_five_letter)
five_letter_tab <- table(five_letter_little)
#most frequent five-letter words with their frequencies
sort(five_word_rep, decreasing = TRUE)[1:10]
five_letter_little_2 <- five_letter_little
#The difference between all the words and 5-word words
unique_all_word <-unique(clean_words)
unique_five_words <-unique(five_letter_little)
Number_dif <- length(unique_all_word)-length(unique_five_words)
Number_dif
#clean data
clean_words <- words_html[-str_which(words_html,"[^a-z, ]+")]
clean_five_letter <-str_subset(clean_words, "^.....$")
five_letter_little<- str_to_lower(clean_five_letter)
five_letter_tab <- table(five_letter_little)
#most frequent five-letter words with their frequencies
sort(five_word_rep, decreasing = TRUE)[1:10]
five_letter_little_2 <- five_letter_little
#The difference between all the words and 5-word words
unique_all_word <-unique(clean_words)
unique_five_words <-unique(five_letter_little)
Number_dif <- length(unique_all_word)-length(unique_five_words)
Number_dif
#clean data
clean_words <- words_html[-str_which(words_html,"[^a-z, ]+")]
clean_five_letter <-str_subset(clean_words, "^.....$")
five_letter_little<- str_to_lower(clean_five_letter)
five_letter_tab <- table(five_letter_little)
#most frequent five-letter words with their frequencies
five_letter_little_2 <- five_letter_little
#The difference between all the words and 5-word words
unique_all_word <-unique(clean_words)
unique_five_words <-unique(five_letter_little)
Number_dif <- length(unique_all_word)-length(unique_five_words)
Number_dif
#most frequent five-letter words with their frequencies
sort(five_word_rep, decreasing = TRUE)[1:10]
