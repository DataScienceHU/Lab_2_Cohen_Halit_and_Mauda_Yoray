new_word_matrix <- rep(1,length(str))
new_word_matrix <- cbind(column_a ,new_word_matrix)
#Create the subject of the columns
colnames(new_word_matrix) <- c("word", "prob")
rownames(new_word_matrix) <- c(1:length(str))
new_word_matrix <- as.data.frame(new_word_matrix)
new_word_matrix[,2] <- as.numeric(new_word_matrix[,2])
#i -Go through every word
for (i in 1:length(str)) {
worde_2 <- unlist(strsplit(str[i],""))
#Go through each letter
for (j in 1:length(worde_2)){
new_word_matrix[i,2] <- new_word_matrix[i,2] * tab_basis[worde_2[j],j]}}
#Show the top-10 words with the highest likelihood
order_words <- new_word_matrix[order(-new_word_matrix$prob),]
return(order_words)}
tab_likelihood<-likelihood_words(unique_five_words)
head(tab_likelihood,10)
# frequency table:
letter_freq_ww5 <-w_words_5 %>% str_split("") %>% # Split to a vector
map(unique) %>%unlist() %>% #one letter per word
table() %>% sort(decreasing = TRUE) %>%
`/`(length(w_words_5)) %>% c()
#frequency table per position:
freq_table_v<-freq_table(w_words_5)
freq_table_v
heatmap(freq_table_v,Colv = NA ,Rowv = NA,scale ="column",xlab = "column",ylab = "letter")
strategy_2 <- function(given_word){
word_list = w_words_5
count <- 0
# make freq function
likelyhood_list_ordered <- likelihood_words(word_list)
guess_word <- likelyhood_list_ordered$word[1]
result <- wordle_match(guess_word, given_word)
while (sum(result) != 5){
count <- count + 1
word_list <- mach_word(guess_word, result,word_list)
likelyhood_list_ordered <- likelihood_words(word_list)
guess_word <- likelyhood_list_ordered$word[1]
result <- wordle_match(guess_word, given_word)
}
return(count)
}
strategy_2 ("mouse")
strategy_1 <- function(unknwon_word, print=FALSE){
unknwon_let <- strsplit(unknwon_word,"")[[1]]
words_con <- likelyhood_list_ordered
turns <- 1
check_word <- words_con[1]
check_let <- strsplit(check_word,"")[[1]]
guess <- rep(1,5)
guess[!check_let==unknwon_let] <- sapply(check_let, function(x) ifelse(!x %in% unknwon_let,0, -1))[!check_let==unknwon_let]
all_check <- c(check_word)
all_guess <- cbind(guess)
record_guess_2 <- list(cbind(check_let, guess))
while (!all(guess==rep(1,5))){
if(print){ #print guess at each turn, as well as the match array
print(c(check_word, turns))
}
turns <- turns+1
words_con <- mach_word(list(all_check, all_guess), words_con)
check_word <- words_con[1]
check_let <- strsplit(check_word,"")[[1]]
guess <- rep(1,5)
guess[!check_let==unknwon_let] <- sapply(check_let, function(x) ifelse(!x %in% unknwon_let,0, -1))[!check_let==unknwon_let]
all_check <- c(all_check, check_word)
all_guess <- cbind(all_guess, guess)
record_guess_2 <- list(cbind(check_let, guess))
}
if(print){ #print guess at each turn, as well as the match array
print(c(check_word, turns))
}
return(turns)
}
strategy_1 <- function(unknwon_word, print=FALSE){
unknwon_let <- strsplit(unknwon_word,"")[[1]]
words_con <- likelyhood_list_ordered
turns <- 1
check_word <- words_con[1]
check_let <- strsplit(check_word,"")[[1]]
guess <- rep(1,5)
guess[!check_let==unknwon_let] <- sapply(check_let, function(x) ifelse(!x %in% unknwon_let,0, -1))[!check_let==unknwon_let]
all_check <- c(check_word)
all_guess <- cbind(guess)
record_guess_2 <- list(cbind(check_let, guess))
while (!all(guess==rep(1,5))){
if(print){ #print guess at each turn, as well as the match array
print(c(check_word, turns))
}
turns <- turns+1
words_con <- mach_word(list(all_check, all_guess), words_con)
check_word <- words_con[1]
check_let <- strsplit(check_word,"")[[1]]
guess <- rep(1,5)
guess[!check_let==unknwon_let] <- sapply(check_let, function(x) ifelse(!x %in% unknwon_let,0, -1))[!check_let==unknwon_let]
all_check <- c(all_check, check_word)
all_guess <- cbind(all_guess, guess)
record_guess_2 <- list(cbind(check_let, guess))
}
if(print){ #print guess at each turn, as well as the match array
print(c(check_word, turns))
}
return(turns)
}
strategy_1("mose",TRUE)
strategy_2 <- function(given_word){
word_list = w_words_5
count <- 0
# make freq function
likelyhood_list_ordered <- likelihood_words(word_list)
guess_word <- likelyhood_list_ordered$word[1]
result <- wordle_match(guess_word, given_word)
while (sum(result) != 5){
count <- count + 1
word_list <- mach_word(guess_word, result,word_list)
likelyhood_list_ordered <- likelihood_words(word_list)
guess_word <- likelyhood_list_ordered$word[1]
result <- wordle_match(guess_word, given_word)
}
return(count)
}
strategy_2 ("mouse")
likelyhood_list_ordered <- likelihood_words(word_list)
likelyhood_list_ordered <- likelihood_words(w_words_5)
likelyhood_list_ordered <- likelihood_words(unique_five_words)
strategy_2 <- function(given_word){
word_list = unique_five_words
count <- 0
# make freq function
likelyhood_list_ordered <- likelihood_words(word_list)
guess_word <- likelyhood_list_ordered$word[1]
result <- wordle_match(guess_word, given_word)
while (sum(result) != 5){
count <- count + 1
word_list <- mach_word(guess_word, result,word_list)
likelyhood_list_ordered <- likelihood_words(word_list)
guess_word <- likelyhood_list_ordered$word[1]
result <- wordle_match(guess_word, given_word)
}
return(count)
}
strategy_2 ("mouse")
strategy_1 <- function(unknwon_word, print=FALSE){
unknwon_let <- strsplit(unknwon_word,"")[[1]]
words_con <- likelyhood_list_ordered
turns <- 1
check_word <- words_con[1]
check_let <- strsplit(check_word,"")[[1]]
guess <- rep(1,5)
guess[!check_let==unknwon_let] <- sapply(check_let, function(x) ifelse(!x %in% unknwon_let,0, -1))[!check_let==unknwon_let]
all_check <- c(check_word)
all_guess <- cbind(guess)
record_guess_2 <- list(cbind(check_let, guess))
while (!all(guess==rep(1,5))){
if(print){ #print guess at each turn, as well as the match array
print(c(check_word, turns))
}
turns <- turns+1
words_con <- mach_word(list(all_check, all_guess), words_con)
check_word <- words_con[1]
check_let <- strsplit(check_word,"")[[1]]
guess <- rep(1,5)
guess[!check_let==unknwon_let] <- sapply(check_let, function(x) ifelse(!x %in% unknwon_let,0, -1))[!check_let==unknwon_let]
all_check <- c(all_check, check_word)
all_guess <- cbind(all_guess, guess)
record_guess_2 <- list(cbind(check_let, guess))
}
if(print){ #print guess at each turn, as well as the match array
print(c(check_word, turns))
}
return(turns)
}
strategy_1("mose",TRUE)
strategy11 <-function(guss,coreect_word){
#function frome 5.b
res_word <- wordle_match(guss,coreect_word)
all_words <- mach_word(guss,res_word,unique_five_words )
#function frome 4.c
tab_likelihood_2-likelihood_words(all_words )
top_likel <-head(tab_likelihood,10)
return(top_likel)}
strategy_11(nouse,mouse)
strategy_11(nouse,mouse)
strategy_11 <-function(guss,coreect_word){
#function frome 5.b
res_word <- wordle_match(guss,coreect_word)
all_words <- mach_word(guss,res_word,unique_five_words )
#function frome 4.c
tab_likelihood_2-likelihood_words(all_words )
top_likel <-head(tab_likelihood,10)
return(top_likel)}
strategy_11(nouse,mouse)
strategy_11 <-function(guss,coreect_word){
#function frome 5.b
res_word <- wordle_match(guss,coreect_word)
all_words <- mach_word(guss,res_word,unique_five_words )
#function frome 4.c
tab_likelihood_2-likelihood_words(all_words )
top_likel <-head(tab_likelihood,10)
return(top_likel)}
strategy_11("nouse","mouse")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
# Read the html into r:
webpage <- read_html(url)
# In line 35, We are creating the first paragraph, and then extract the first line out of it. In line 36 we're returning the sentence.
first_sentence <- webpage %>% html_nodes("div") %>% html_text()
first_sentence[1]
words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
words_html <- words_html[[1]]
words_html <- words_html[words_html!=""]
# Counting words
print(length(words_html))
# Length words
words_n <- nchar(words_html)
# Longest word, mean, and median
max(words_n)
mean(words_n)
median(words_n)
# Create frequency table
freq_words <- sort(table(unlist(words_html)),
decreasing = TRUE)
# Most common word
mcw <- which.max(freq_words)
mcw
# the distribution of word
tab_n <- table(str_length(words_html))/length(words_html)
barplot(tab_n,main="Word Length Distribution")
moby_text <- html_text2(webpage)
cut_text <- str_split(moby_text, "\rErromangoan.\t\r\n\r H2 anchor\r\n\r\n\n\n\n\n\r\n\r ")[[1]][2]
chapters <- strsplit(cut_text, "\r\n\n\r\n\n\r \r \r\n\n\r\n\r\n\n\n\n\n\r\n\r ")
chapters <- chapters[[1]]
chapters <- str_to_lower(chapters)
chapters <- gsub('[[:punct:]]+',"",chapters)
x_chapter_num <- c()
y_words_per_chapter <- c()
for (i in 1:length(chapters)){
fixed_chapter_i <- str_replace_all(chapters[i], "\\s+", " ")
splitsplat <- str_split(fixed_chapter_i, " ")
splitsplat <- c(splitsplat)
splitsplat <- splitsplat[[1]]
x_chapter_num[i] <- i
y_words_per_chapter[i] <- length(splitsplat)
}
barplot(y_words_per_chapter, main = "Number of Words Per Chapter",
xlab = "Chapter Number", ylab = "Words Number", names.arg = x_chapter_num,
col = "darkred")
Q2a <- function(word_query, chapters_num){
word_query <- str_to_lower(word_query)
relative_freq <- c()
counter <- 1
for (i in as.numeric(chapters_num)){
relative_freq[counter] <- (str_count(chapters[i], word_query)/y_words_per_chapter[i])
counter <- counter + 1
}
return(relative_freq)
}
ahab_plot <- Q2a("Ahab", c(1:137))
barplot(ahab_plot, main = "Freq VS. Chapter for Ahab",
xlab = "Chapter Number", ylab = "Word Freq", names.arg = x_chapter_num,
col = "darkblue")
moby_plot <- Q2a("Moby", c(1:137))
barplot(moby_plot, main = "Freq VS. Chapter for Moby",
xlab = "Chapter Number", ylab = "Word Freq", names.arg = x_chapter_num,
col = "darkgreen")
sea_plot <- Q2a("sea", c(1:137))
barplot(sea_plot, main = "Freq VS. Chapter for sea",
xlab = "Chapter Number", ylab = "Word Freq", names.arg = x_chapter_num,
col = "yellow")
total_words_amount <- sum(y_words_per_chapter)
total_words_amount
full_book_string <- webpage %>% html_nodes("body") %>% html_text()
full_book_string <- str_replace_all(full_book_string, "\\s+", " ")
full_book_string <- str_to_lower(full_book_string)
full_book_string <- gsub('[[:punct:]]+',"",full_book_string)
full_book_string <- gsub('[[:digit:]]+', "", full_book_string)
full_book_string <- str_split(full_book_string, " ")
full_book_string <- full_book_string[[1]]
full_book_string <- str_subset(full_book_string, ".+")
full_book_df <- data.frame(word = full_book_string)
words_data <- full_book_df %>% group_by(word) %>% count()
Q3a <- function(word_query){
word_query <- str_to_lower(word_query)
total_word_count <- c()
for (i in 1:137){
total_word_count[i] <- str_count(chapters[i], word_query)
}
freq = sum(total_word_count)/total_words_amount
return (freq^2)
}
words_data$frequency <- words_data$n/total_words_amount
words_data$squared_freq <- (words_data$frequency)^2
sum(words_data$squared_freq)
bob_alice_same_word <- 0
for (i in 1:100000){
event1 <- sample(full_book_string, 1)
event2 <- sample(full_book_string, 1)
if (event1 == event2){
bob_alice_same_word <- bob_alice_same_word + 1}}
freq_bob_alice <- bob_alice_same_word/100000
unique_full_book <- unique(full_book_string)
# Clean data
clean_words <- words_html[-str_which(words_html,"[^a-z, ]+")]
clean_five_letter <-str_subset(clean_words, "^.....$")
five_letter_little<- str_to_lower(clean_five_letter)
five_letter_tab <- table(five_letter_little)
# Most frequent five-letter words with their frequencies
sort(five_letter_tab, decreasing = TRUE)[1:10]
five_letter_little_2 <- five_letter_little
# The difference between all the words and 5-word words
unique_all_word <-unique(clean_words)
unique_five_words <-unique(five_letter_little)
number_dif <- length(unique_all_word)-length(unique_five_words)
number_dif
freq_table <- function(str) {
# We create matrix that help us to see the freq present
freq_mat <- matrix(0,26,5)
colnames(freq_mat) <- c("1","2","3","4","5")
rownames(freq_mat) <- letters[1:26]
sum <- 1
#i -Go through every word
#Go through each letter
for (i in str){
for (j in unlist(strsplit(i,""))){
freq_mat[j,sum] <-  freq_mat[j,sum] + 1
sum <- sum + 1
if (sum == 6){sum <- 1}}}
freq_mat <-freq_mat/ colSums(freq_mat)[1]
return( freq_mat)}
freq_table_var <-freq_table(unique_five_words)
freq_table_var
# Create heat map
heatmap(freq_table_var,Colv = NA ,Rowv = NA,scale ="column",xlab = "column",ylab = "letter")
# Here, too, we use a matrix calculation in order to show the top-10 words with the highest likelihood.
likelihood_words<- function(str) {
tab_basis<- freq_table(str)
# Normalized to probabilities
column_a <- as.matrix(str)
new_word_matrix <- rep(1,length(str))
new_word_matrix <- cbind(column_a ,new_word_matrix)
# Create the subject of the columns
colnames(new_word_matrix) <- c("word", "prob")
rownames(new_word_matrix) <- c(1:length(str))
new_word_matrix <- as.data.frame(new_word_matrix)
new_word_matrix[,2] <- as.numeric(new_word_matrix[,2])
# i - Goes through every word
for (i in 1:length(str)) {
worde_2 <- unlist(strsplit(str[i],""))
# Goes through each letter
for (j in 1:length(worde_2)){
new_word_matrix[i,2] <- new_word_matrix[i,2] * tab_basis[worde_2[j],j]}}
# Shows the top-10 words with the highest likelihood
order_words <- new_word_matrix[order(-new_word_matrix$prob),]
return(order_words)}
tab_likelihood<-likelihood_words(unique_five_words)
head(tab_likelihood,10)
#read list
url2 <- 'https://raw.githubusercontent.com/DataScienceHU/Lab_2_Cohen_Halit_and_Mauda_Yoray/main/sgb-words.txt'
# Read the html into r:
w_words <- read_html(url2)
w_words_5 <- w_words %>% html_text()
w_words_5 <- w_words_5 %>% str_split("\n") %>% unlist()
class(w_words_5)
# frequency table:
letter_freq_ww5 <-w_words_5 %>% str_split("") %>% # Split to a vector
map(unique) %>%unlist() %>% #one letter per word
table() %>% sort(decreasing = TRUE) %>%
`/`(length(w_words_5)) %>% c()
#frequency table per position:
freq_table_v<-freq_table(w_words_5)
freq_table_v
heatmap(freq_table_v,Colv = NA ,Rowv = NA,scale ="column",xlab = "column",ylab = "letter")
length(w_words_5)
length(unique_five_words)
# Helper function:
wordle_match <- function(guess, word)  # 1: correct location, -1: wrong location, 0: missing
{
L <- nchar(guess)
match <- rep(0, L)
for(i in 1:L)
{
if(grepl(substr(guess, i, i), word, fixed=TRUE))
{match[i] = -1}
if(substr(guess, i, i) == substr(word, i, i))
{      match[i] = 1}
}
return(match)
}
mach_word<- function(guess,results,dictionary){
words_d <- dictionary
#i -Go through every word
#j -Go through every Single result
for (i in dictionary){
for (j in 1:length(results)){
match <- wordle_match(guess[[j]], i)
word_match_test <- match == results[[j]]
#We will leave only what had a match
if (length(word_match_test[word_match_test == TRUE]) != 5) {
words_d <- words_d[words_d != i]}}}
return(words_d)}
#chek the function
gues<- list("south", "north")
res <- list(c(-1, 1, 1, 0, 0), c(0, 1, 0, 0, 0))
mach_word(gues,res,w_words_5)
strategy_1 <- function(unknown_word){
unknown_word <- str_to_lower(unknown_word)
added <- c()
condition <- FALSE
counter <- 0
while (condition == FALSE){
comb <- sample(letters, 5)
comb <- paste(comb, collapse = "")
match <- wordle_match(comb, unknown_word)
split_comb <- str_split(comb, "")
split_comb <- split_comb[[1]]
added[which(match == 1)] <- split_comb[which(match == 1)]
added2 <- paste(added, collapse = "")
if (added2 != unknown_word) {
counter <- counter + 1
} else {
condition <- TRUE
}
}
return(counter)
}
test <- strategy_1("mouse")
test
E <- 0 # The expectancy
E_v <- c()
probability <- 0
cumulative_prob <- c()
for (k in 1:10000){
E_v[k] <- ((1-(25/26)**k)**5 - (1-(25/26)**(k-1))**5)
E <- E + k*E_v[k]
probability <- probability + E_v[k]
cumulative_prob[k] <- probability
}
E
# 1 - Drawing 5 letters from our list of 5 letter words
random_100 <- sample(unique_five_words, 100)
num_of_tries <- c()
# 2 - For each unknown word, we run the guessing strategy implemented in (a.) and record the number of turns
for (i in 1:length(random_100)){
num_of_tries[i] <- strategy_1(random_100[i])
}
# Step 3 - Computing the AVG
avg_number_of_tries <- sum(num_of_tries)/100
plot(seq(1,max(num_of_tries)),cumulative_prob[1:max(num_of_tries)], xlab = 'Num of Tries', ylab = 'Probability')
lines(ecdf(num_of_tries), col= 'yellow')
strategy_2 <- function(given_word){
word_list = unique_five_words
count <- 0
# make freq function
likelyhood_list_ordered <- likelihood_words(word_list)
guess_word <- likelyhood_list_ordered$word[1]
result <- wordle_match(guess_word, given_word)
while (sum(result) != 5){
count <- count + 1
word_list <- mach_word(guess_word, result,word_list)
likelyhood_list_ordered <- likelihood_words(word_list)
guess_word <- likelyhood_list_ordered$word[1]
result <- wordle_match(guess_word, given_word)
}
return(count)
}
Q.7.b <- function(){
#  take 100 words random in randome
word_unknow <- unique_five_words[sample(1:length(unique_five_words), 1000, TRUE)]
#df_strategy_2
rec2 <- sapply(word_unknow, strategy_2)
ave2 <- mean(rec2)
ecdf2 <- my_ecdf(1:25, sort(rec2))
df2 = data.frame(x=1:25, CDF=CDF_2, type="strategy_2")
#df_strategy_3
rec3 <- sapply(word_unknow, strategy_3)
ave3 <- mean(rec3)
ecdf3 <- my_ecdf(1:20, sort(rec3))
df3 = data.frame(x=1:20, CDF=CDF_3, type="strategy_3")
#union
df_ecdf <- rbind(df2,df3)
ggplot(df_ecdf) +
geom_line(aes(x, CDF, colour=type))
}
# Here, too, we use a matrix calculation in order to show the top-10 words with the highest likelihood.
likelihood_words<- function(words) {
tab_basis<- freq_table(words)
# Normalized to probabilities
column_a <- as.matrix(words)
new_word_matrix <- rep(1,length(words))
new_word_matrix <- cbind(column_a ,new_word_matrix)
# Create the subject of the columns
colnames(new_word_matrix) <- c("word", "prob")
rownames(new_word_matrix) <- c(1:length(words))
new_word_matrix <- as.data.frame(new_word_matrix)
new_word_matrix[,2] <- as.numeric(new_word_matrix[,2])
# i - Goes through every word
for (i in 1:length(words)) {
worde_2 <- unlist(strsplit(words[i],""))
# Goes through each letter
for (j in 1:length(worde_2)){
new_word_matrix[i,2] <- new_word_matrix[i,2] * tab_basis[worde_2[j],j]}}
# Shows the top-10 words with the highest likelihood
order_words <- new_word_matrix[order(-new_word_matrix$prob),]
return(order_words)}
tab_likelihood<-likelihood_words(unique_five_words)
head(tab_likelihood,10)
