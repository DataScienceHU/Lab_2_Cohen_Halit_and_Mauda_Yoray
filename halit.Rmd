---
title: "52414 - lab 2 "
author: "Yoray Mauda 315874404 and Halit Cohen 318356854"
date: "09/06/2022"
output: html_document
---
```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, .. 
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext) 
library(rvest)
```  

### Question 1

In this question, we will wrangle and scrape data from the book "Moby Dick", extract information, print text, make numerous manipulation on the text, and also create different distributions for it.

###### A

First, we will fetch the HTML, and then we will print the first line.

```{r, include=FALSE}
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
# Read the html into r:
webpage <- read_html(url)
```  

```{r}
# In line 35, We are creating the first paragraph, and then extract the first line out of it. In line 36 we're returning the sentence.
first_sentence <- webpage %>% html_nodes("div") %>% html_text()
first_sentence[1]
```

##### B

```{r}
words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
words_html <- words_html[[1]]
words_html <- words_html[words_html!=""]
#count words
print(length(words_html))
# length words
words_n <-nchar(words_html)
#longest word, mean, median
max(words_n)
mean(words_n)
median(words_n)
# Create frequency table
freq_words <- sort(table(unlist(words_html)),
               decreasing = TRUE)
#most common word
mcw <-which.max(freq_words)
mcw
# the distribution of word 
tab_n<-table(str_length(words_html))/length(words_html)
barplot(tab_n,main="word length Distribution")
```

###c
```{r}
sort(table(words_html), decreasing = TRUE)[1:10]
```
Not surprisingly, the most common words are conjunction or body pronouns.  

### Question 2

###### A

In this section we will divide the text into chapters, and will plot the count of the number of words per each episode.

```{r}
moby_text <- html_text2(webpage)
```

To discard the beginning until the EXTRACT section, We will use `str_split` and remove the beginning.

```{r}
cut_text <- str_split(moby_text, "\rErromangoan.\t\r\n\r H2 anchor\r\n\r\n\n\n\n\n\r\n\r ")[[1]][2]
```

We will not print the results we have received because it is long, but we have notices that between chapters we have division that looks like `\r\n\n\r\n\n\r \r \r\n\n\r\n\r\n\n\n\n\n\r\n\r `. Thus, we will split our text based on this division.

```{r}
chapters <- strsplit(cut_text, "\r\n\n\r\n\n\r \r \r\n\n\r\n\r\n\n\n\n\n\r\n\r ")
chapters <- chapters[[1]]
```

Now, for plotting the data, we will loop over the chapters and extract the wanted data for our plot

```{r}
  x_chapter_num <- c()
  y_words_per_chapter <- c()
  for (i in 1:length(chapters)){
    fixed_chapter_i <- str_replace_all(chapters[i], "\\s+", " ")
    splitsplat <- str_split(fixed_chapter_i, " ")
    splitsplat <- c(splitsplat)
    splitsplat <- splitsplat[[1]]
    x_chapter_num[i] <- i
    y_words_per_chapter[i] <- length(splitsplat)
  }
barplot(y_words_per_chapter, main = "Number of Words Per Chapter",
        xlab = "Chapter Number", ylab = "Words Number", names.arg = x_chapter_num,
        col = "darkred")
```
###### B

For this section we will create a function that will compute the frequency of a word in each given chapters. we will check the function and its trend in the words `Mody`, `Ahab`, and `sea`.

```{r}
Q2a <- function(word_query, chapters_num){
  relative_freq <- c()
  counter <- 1
  for (i in as.numeric(chapters_num)){
    relative_freq[counter] <- (str_count(chapters[i], word_query)/y_words_per_chapter[i])
    counter <- counter + 1
  }
return(relative_freq)
}

ahab_plot <- Q2a("Ahab", c(1:137))
barplot(ahab_plot, main = "Freq VS. Chapter for Ahab",
        xlab = "Chapter Number", ylab = "Word Freq", names.arg = x_chapter_num,
        col = "darkblue")
moby_plot <- Q2a("Moby", c(1:137))
barplot(moby_plot, main = "Freq VS. Chapter for Moby",
        xlab = "Chapter Number", ylab = "Word Freq", names.arg = x_chapter_num,
        col = "darkgreen")
sea_plot <- Q2a("sea", c(1:137))
barplot(sea_plot, main = "Freq VS. Chapter for sea",
        xlab = "Chapter Number", ylab = "Word Freq", names.arg = x_chapter_num,
        col = "yellow")
```

As we can see, the most frequent word is `sea`, which also make sense based on the book's subject. the least frequent word is `Moby`, who barely shows in the book. For `Ahab`, we hear about him in the beginning of the book, and at the end more frequently.

###4
###a
```{r, cache=TRUE}
#clean data
clean_words <- words_html[-str_which(words_html,"[^a-z, ]+")] 
clean_five_letter <-str_subset(clean_words, "^.....$")
five_letter_little<- str_to_lower(clean_five_letter)
five_letter_tab <- table(five_letter_little)
#most frequent five-letter words with their frequencies
sort(five_letter_tab, decreasing = TRUE)[1:10]
five_letter_little_2 <- five_letter_little
#The difference between all the words and 5-word words
unique_all_word <-unique(clean_words)
unique_five_words <-unique(five_letter_little)
Number_dif <- length(unique_all_word)-length(unique_five_words)
Number_dif
```
###b
```{r}
letter_freq <-
  five_letter_little_2 %>%
  # Split each word into a vector of letters
  str_split("") %>%
  # Keep one of each letter per word
  map(unique) %>%
  # Unlist into a big vector of letters
  unlist() %>%
  # Count the letters (each appearance in a word)
  table() %>%
  # Most popular letters first
  sort(decreasing = TRUE) %>%
  # Turn into frequency table
  `/`(length(five_letter_little_2)) %>%
  # Remove attributes from table()
  c()
letter_freq_pos <-
  tibble(word = five_letter_little_2) %>%
  select(word) %>%
  mutate(letter = word) %>%
  tidyr::separate_rows(letter, sep = "") %>%
  filter(letter != "") %>%
  group_by(word) %>%
  mutate(position = row_number()) %>%
  group_by(letter, position) %>%
  summarize(n = n(), .groups = "drop") %>%
  mutate(
    five_letter_little_2 = letter_freq[letter] * length(!!five_letter_little_2),
    freq = n / five_letter_little_2
  ) %>%
  select(-n, -five_letter_little_2) %>%
  tidyr::pivot_wider(
    names_from = position,
    values_from = freq,
    values_fill = 0,
    names_prefix = "p"
  )
letter_freq_pos
```

```{r, cache=TRUE}
# Helper function: 
wordle_match <- function(guess, word)  # 1: correct location, -1: wrong location, 0: missing
{
  L <- nchar(guess)
  match <- rep(0, L)
  for(i in 1:L)
  {
    if(grepl(substr(guess, i, i), word, fixed=TRUE))
      {match[i] = -1}
    if(substr(guess, i, i) == substr(word, i, i))
    {      match[i] = 1}
  }
  
  return(match)
}
```


